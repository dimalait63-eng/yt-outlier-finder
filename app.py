# app.py ‚Äî Ultra Efficient MostPopular Outlier Finder (NO SEARCH, LOW QUOTA)
#
# ‚úÖ –ù–∏–∫–∞–∫–∏—Ö search.list (–∫–æ—Ç–æ—Ä—ã–π —Å–∂–∏—Ä–∞–µ—Ç –∫–≤–æ—Ç—É)
# ‚úÖ –¢–æ–ª—å–∫–æ videos.list(chart=mostPopular) + channels.list
# ‚úÖ –í—ã–±–æ—Ä —Å—Ç—Ä–∞–Ω—ã (regionCode)
# ‚úÖ –£–±–∏—Ä–∞–µ–º Shorts/–∫–æ—Ä–æ—Ç–∫–∏–µ (–ø–æ duration)
# ‚úÖ –§–∏–ª—å—Ç—Ä: –∫–∞–Ω–∞–ª—ã <= 10k subs + views + ratio + views/day
# ‚úÖ –ö–∞—Ä—Ç–æ—á–∫–∏ —Å –æ–±–ª–æ–∂–∫–∞–º–∏ + —Ç–∞–±–ª–∏—Ü–∞ + —ç–∫—Å–ø–æ—Ä—Ç CSV
#
# –ó–∞–ø—É—Å–∫:
#   pip install streamlit google-api-python-client python-dotenv pandas
#   streamlit run app.py
#
# .env:
#   YOUTUBE_API_KEY=–≤–∞—à_–∫–ª—é—á
#
# Streamlit Cloud:
#   Settings ‚Üí Secrets:
#   YOUTUBE_API_KEY="–≤–∞—à_–∫–ª—é—á"

import os
import re
from datetime import datetime, timezone

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# ---------- init ----------
load_dotenv()
API_KEY = os.getenv("YOUTUBE_API_KEY", "").strip()

st.set_page_config(page_title="MostPopular Outlier Finder (Low Quota)", layout="wide")
st.title("MostPopular Outlier Finder (–±–µ–∑ –ø–æ–∏—Å–∫–∞, —ç–∫–æ–Ω–æ–º–Ω–æ –ø–æ –∫–≤–æ—Ç–µ)")

if not API_KEY:
    st.error("–ù–µ –Ω–∞–π–¥–µ–Ω YOUTUBE_API_KEY. –î–æ–±–∞–≤—å –≤ .env –∏–ª–∏ –≤ Streamlit Secrets.")
    st.stop()

youtube = build("youtube", "v3", developerKey=API_KEY)

# ---------- helpers ----------
DUR_RE = re.compile(r"PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?")

def iso_duration_to_seconds(d: str) -> int:
    m = DUR_RE.fullmatch(d or "")
    if not m:
        return 0
    h = int(m.group(1) or 0)
    mi = int(m.group(2) or 0)
    s = int(m.group(3) or 0)
    return h * 3600 + mi * 60 + s

def age_days(published_at: str) -> float:
    dt = datetime.fromisoformat(published_at.replace("Z", "+00:00"))
    days = (datetime.now(timezone.utc) - dt).total_seconds() / 86400
    return max(days, 0.1)

def fmt_int(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return "‚Äî"
    try:
        return f"{int(x):,}".replace(",", " ")
    except Exception:
        return "‚Äî"

def friendly_http_error(e: HttpError) -> str:
    try:
        content = e.content.decode("utf-8", errors="ignore")
    except Exception:
        content = str(e)
    return f"{e}\n\n{content}"

# ---------- API ----------
@st.cache_data(ttl=3600)
def fetch_categories(region_code: str):
    r = youtube.videoCategories().list(part="snippet", regionCode=region_code).execute()
    cats = []
    for it in r.get("items", []):
        sn = it.get("snippet", {})
        if sn.get("assignable") is True:
            cats.append((it["id"], sn.get("title", it["id"])))
    cats.sort(key=lambda x: x[1].lower())
    return cats

@st.cache_data(ttl=1800)
def most_popular_video_ids(region_code: str, pages: int, per_page: int, category_id: str | None):
    ids = []
    page_token = None
    for _ in range(int(pages)):
        params = {
            "part": "snippet",
            "chart": "mostPopular",
            "regionCode": region_code,
            "maxResults": int(per_page),
        }
        if category_id:
            params["videoCategoryId"] = str(category_id)
        if page_token:
            params["pageToken"] = page_token

        r = youtube.videos().list(**params).execute()
        ids.extend([it["id"] for it in r.get("items", [])])

        page_token = r.get("nextPageToken")
        if not page_token:
            break

    return list(dict.fromkeys(ids))

@st.cache_data(ttl=1800)
def fetch_videos(video_ids: list[str]):
    out = []
    for i in range(0, len(video_ids), 50):
        chunk = video_ids[i:i+50]
        r = youtube.videos().list(
            part="snippet,statistics,contentDetails",
            id=",".join(chunk)
        ).execute()

        for it in r.get("items", []):
            sn = it.get("snippet", {})
            stt = it.get("statistics", {})
            cd = it.get("contentDetails", {})

            thumbs = sn.get("thumbnails", {})
            thumb_url = None
            for k in ["maxres", "standard", "high", "medium", "default"]:
                if k in thumbs and "url" in thumbs[k]:
                    thumb_url = thumbs[k]["url"]
                    break

            out.append({
                "videoId": it.get("id"),
                "title": sn.get("title", ""),
                "channelId": sn.get("channelId", ""),
                "channelTitle": sn.get("channelTitle", ""),
                "publishedAt": sn.get("publishedAt", ""),
                "views": int(stt.get("viewCount", 0)),
                "duration_iso": cd.get("duration", ""),
                "thumbnail": thumb_url,
            })
    return out

@st.cache_data(ttl=1800)
def fetch_channels_subs(channel_ids: list[str]):
    result = {}
    channel_ids = [c for c in channel_ids if c]
    for i in range(0, len(channel_ids), 50):
        chunk = channel_ids[i:i+50]
        r = youtube.channels().list(part="statistics", id=",".join(chunk)).execute()
        for it in r.get("items", []):
            stt = it.get("statistics", {})
            subs = stt.get("subscriberCount")
            result[it["id"]] = int(subs) if subs is not None else None
    return result

# ---------- UI ----------
COMMON_COUNTRIES = [
    ("US", "United States"),
    ("GB", "United Kingdom"),
    ("CA", "Canada"),
    ("AU", "Australia"),
    ("DE", "Germany"),
    ("FR", "France"),
    ("NL", "Netherlands"),
    ("ES", "Spain"),
    ("IT", "Italy"),
    ("BR", "Brazil"),
    ("MX", "Mexico"),
    ("JP", "Japan"),
    ("KR", "South Korea"),
    ("IN", "India"),
    ("RU", "Russia"),
    ("UA", "Ukraine"),
    ("PL", "Poland"),
    ("SE", "Sweden"),
    ("NO", "Norway"),
    ("TR", "Turkey"),
]

with st.sidebar:
    st.header("–°—Ç—Ä–∞–Ω–∞")
    country_choice = st.selectbox(
        "regionCode",
        options=COMMON_COUNTRIES,
        index=0,
        format_func=lambda x: f"{x[1]} ({x[0]})",
    )
    region_code = country_choice[0]

    st.header("–û—Ö–≤–∞—Ç (–¥—ë—à–µ–≤–æ –ø–æ –∫–≤–æ—Ç–µ)")
    scan_by_categories = st.checkbox("–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (—à–∏—Ä–µ)", value=True)
    pages = st.slider("–°—Ç—Ä–∞–Ω–∏—Ü –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é", 1, 10, 3, 1)
    per_page = st.selectbox("–í–∏–¥–µ–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É", [10, 25, 50], index=2)

    st.header("–§–∏–ª—å—Ç—Ä—ã")
    exclude_shorts = st.checkbox("–£–±—Ä–∞—Ç—å Shorts/–∫–æ—Ä–æ—Ç–∫–∏–µ", value=True)
    min_seconds = st.slider("–ú–∏–Ω. –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫)", 60, 3600, 120, 30, disabled=not exclude_shorts)

    # —Ç–≤–æ—è —Ü–µ–ª—å: –∫–∞–Ω–∞–ª—ã <= 10k
    max_subs = st.number_input("–ú–∞–∫—Å. –ø–æ–¥–ø–∏—Å—á–∏–∫–∏ –∫–∞–Ω–∞–ª–∞", min_value=0, value=10_000, step=500)
    min_views = st.number_input("–ú–∏–Ω. –ø—Ä–æ—Å–º–æ—Ç—Ä—ã", min_value=0, value=50_000, step=10_000)
    min_ratio = st.number_input("–ú–∏–Ω. Views/Subs (–µ—Å–ª–∏ subs –≤–∏–¥–Ω—ã)", min_value=0.0, value=3.0, step=1.0)

    st.header("–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞/–≤–∏–¥")
    sort_mode = st.selectbox("–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ", ["views_per_day", "ratio", "views", "date"], index=0)
    view_mode = st.radio("–í–∏–¥", ["–ö–∞—Ä—Ç–æ—á–∫–∏ (—Å –æ–±–ª–æ–∂–∫–∞–º–∏)", "–¢–∞–±–ª–∏—Ü–∞"], index=0)

    run = st.button("üîé –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å")

if not run:
    st.write("–í—ã–±–µ—Ä–∏ —Å—Ç—Ä–∞–Ω—É —Å–ª–µ–≤–∞ ‚Üí –Ω–∞–∂–º–∏ **–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å**.")
    st.stop()

errors = []
try:
    video_ids = []

    if scan_by_categories:
        cats = fetch_categories(region_code)
        cat_options = [f"{title} ({cid})" for cid, title in cats]
        default_pick = cat_options[: min(10, len(cat_options))]

        selected = st.multiselect(
            "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–≤—ã–±–µ—Ä–∏ –±–æ–ª—å—à–µ ‚Äî –±–æ–ª—å—à–µ –æ—Ö–≤–∞—Ç)",
            options=cat_options,
            default=default_pick,
        )
        selected_ids = []
        for s in selected:
            cid = s.split("(")[-1].split(")")[0].strip()
            selected_ids.append(cid)

        # –µ—Å–ª–∏ —é–∑–µ—Ä –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–ª ‚Äî –≤–æ–∑—å–º—ë–º –≤—Å–µ (–Ω–æ —ç—Ç–æ –¥–æ–ª—å—à–µ)
        if not selected_ids:
            selected_ids = [cid for cid, _ in cats]

        for cid in selected_ids:
            video_ids.extend(most_popular_video_ids(region_code, pages, per_page, cid))
    else:
        video_ids.extend(most_popular_video_ids(region_code, pages, per_page, None))

    video_ids = list(dict.fromkeys(video_ids))

    vids = fetch_videos(video_ids)
    subs_map = fetch_channels_subs(list({v["channelId"] for v in vids}))

    rows = []
    for v in vids:
        secs = iso_duration_to_seconds(v.get("duration_iso", ""))

        if exclude_shorts and secs < int(min_seconds):
            continue

        subs = subs_map.get(v["channelId"])
        days = age_days(v["publishedAt"]) if v.get("publishedAt") else None
        vpd = (v["views"] / days) if days else None

        ratio = None
        if subs and subs > 0:
            ratio = v["views"] / subs

        if v["views"] < int(min_views):
            continue
        if subs is not None and subs > int(max_subs):
            continue
        if ratio is not None and ratio < float(min_ratio):
            continue

        rows.append({
            "title": v["title"],
            "channel": v["channelTitle"],
            "subs": subs,
            "views": v["views"],
            "views_per_day": round(vpd, 2) if vpd is not None else None,
            "ratio": round(ratio, 2) if ratio is not None else None,
            "duration_sec": secs,
            "publishedAt": v["publishedAt"],
            "thumbnail": v["thumbnail"],
            "url": f"https://www.youtube.com/watch?v={v['videoId']}",
        })

except HttpError as e:
    errors.append(friendly_http_error(e))

if errors:
    st.error("–û—à–∏–±–∫–∞ API (–∫–≤–æ—Ç–∞/–∫–ª—é—á/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞).")
    st.code("\n\n".join(errors))
    st.stop()

if not rows:
    st.info(
        "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã.\n\n"
        "–í–∞–∂–Ω–æ: mostPopular —Ä–µ–¥–∫–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∞–Ω–∞–ª—ã ‚â§10k.\n\n"
        "–ß—Ç–æ–±—ã —á–∞—â–µ –Ω–∞—Ö–æ–¥–∏–ª–æ:\n"
        "- —Å–Ω–∏–∑–∏—Ç—å min_views –¥–æ 10k‚Äì20k\n"
        "- —Å–Ω–∏–∑–∏—Ç—å min_ratio –¥–æ 0‚Äì1\n"
        "- —É–≤–µ–ª–∏—á–∏—Ç—å pages/per_page\n"
        "- –≤—ã–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"
    )
    st.stop()

df = pd.DataFrame(rows)

# sort
if sort_mode == "views_per_day":
    df["_sort"] = df["views_per_day"].fillna(-1)
    df = df.sort_values("_sort", ascending=False).drop(columns=["_sort"])
elif sort_mode == "ratio":
    df["_sort"] = df["ratio"].fillna(-1)
    df = df.sort_values("_sort", ascending=False).drop(columns=["_sort"])
elif sort_mode == "views":
    df = df.sort_values("views", ascending=False)
else:
    df = df.sort_values("publishedAt", ascending=False)

st.success(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {len(df)} (–∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(video_ids)})")

if view_mode.startswith("–ö–∞—Ä—Ç–æ—á–∫–∏"):
    for _, r in df.iterrows():
        c1, c2 = st.columns([1, 3])
        with c1:
            if r.get("thumbnail"):
                st.image(r["thumbnail"], use_container_width=True)
            else:
                st.write("üñº –ù–µ—Ç –ø—Ä–µ–≤—å—é")
        with c2:
            st.markdown(f"**{r['title']}**")
            st.write(
                f"–ö–∞–Ω–∞–ª: {r['channel']}\n\n"
                f"Subs: {fmt_int(r['subs'])} | Views: {fmt_int(r['views'])} | "
                f"Views/day: {r.get('views_per_day','‚Äî')} | Ratio: {r.get('ratio','‚Äî')}\n\n"
                f"Duration: {fmt_int(r.get('duration_sec'))} sec | Date: {r['publishedAt']}"
            )
            st.markdown(f"[–û—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ]({r['url']})")
        st.divider()
else:
    show = df[["title", "channel", "subs", "views", "views_per_day", "ratio", "duration_sec", "publishedAt", "url"]]
    st.dataframe(show, use_container_width=True)

csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
st.download_button(
    "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV",
    data=csv_bytes,
    file_name=f"mostpopular_outliers_{region_code}.csv",
    mime="text/csv",
)

st.caption(
    "–≠—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ç–∫–æ–Ω–æ–º–Ω–æ –ø–æ –∫–≤–æ—Ç–µ (–±–µ–∑ search). "
    "–ù–æ mostPopular —Ä–µ–¥–∫–æ –≤–∫–ª—é—á–∞–µ—Ç –∫–∞–Ω–∞–ª—ã ‚â§10k. "
    "–ï—Å–ª–∏ —Ö–æ—á–µ—à—å —Ä–µ–∞–ª—å–Ω–æ –º–Ω–æ–≥–æ outliers –º–∞–ª–µ–Ω—å–∫–∏—Ö –∫–∞–Ω–∞–ª–æ–≤ ‚Äî –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å '—ç–∫–æ–Ω–æ–º–Ω—ã–π search' (10‚Äì15 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å)."
)
